This service provides a chat interface for the GPT4All-13b-snoozy AI assistant. It trained on a massive curated corpus of assistant interactions including word problems, multi-turn dialogue, code, poems, songs, and stories.

## Basic Usage

In the "Text generation" tab you can ask questions or give instructions, and see the responses generated by the GPT4All large language model (LLM). Like most LLMs, GPT4All can not access any information not already included in the 8GB parameter file included in the service, which means its answers may be wrong or out-of-date. Always verify the output of a LLM  before using it for anything important ([such a as a court filing](https://apnews.com/article/artificial-intelligence-chatgpt-fake-case-lawyers-d6ae9fa79d0542db9e1455397aef381c)).

## Additional Models

Depending on how you would like to use the service, you may get better results with a model other than GPT4All-13b-snoozy. It is possible to download other LLMs from [huggingface](https://huggingface.co) and upload them to the `/gpt4all/models` directory using the File Browser service. But not all LLM checkpoints are currently supported by the service. You will get the best results with checkpoints that
1. Contain "ggmlv3" somewhere in the name.
2. Contain "q2", "q4", or "q5" somewhere in the name.
3. End in a ".bin" file extension.
4. Are 13b parameters or less.

If you have uploaded a valid checkpoint, you will be able to access it from the "Models" tab of the user interface. Make sure that the "lamma.cpp" runtime is automatically selected. Also make sure that the "Chat settings" are correctly configured for the model of your choice.
